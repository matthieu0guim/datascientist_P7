{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdfeBXwmJlf2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "from google.colab import files  \n",
        "import os  \n",
        "application = files.upload()  \n",
        "application = pd.read_csv(io.BytesIO(application[\"application_train.csv\"]))  "
      ],
      "metadata": {
        "id": "Z2i96CvoT0PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANuhbeYeSUW2",
        "outputId": "39e00142-2f1f-4431-83b4-aa46204400c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/OpenClassroom/P7/data\"\n",
        "application = pd.read_csv(path + '/application_train.csv')\n",
        "bureau_balance = pd.read_csv(path + \"/bureau_balance.csv\", encoding='latin')\n",
        "bureau = pd.read_csv(path + \"/bureau.csv\", encoding='latin')\n",
        "cc = pd.read_csv(path + \"/credit_card_balance.csv\", encoding='latin')\n",
        "ins = pd.read_csv(path + \"/installments_payments.csv\", encoding='latin')\n",
        "pos = pd.read_csv(path + \"/POS_CASH_balance.csv\", encoding='latin')\n",
        "previous = pd.read_csv(path + \"/previous_application.csv\", encoding='latin')\n",
        "sample = pd.read_csv(path + \"/sample_submission.csv\", encoding='latin')"
      ],
      "metadata": {
        "id": "TSIXLo1DS4I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "mc6AcmhQJlf7"
      },
      "outputs": [],
      "source": [
        "def one_hot_encoder(df, nan_as_category = True):\n",
        "    original_columns = list(df.columns)\n",
        "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
        "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
        "    new_columns = [c for c in df.columns if c not in original_columns]\n",
        "    return df, new_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "62Z8O8ZtJlf8"
      },
      "source": [
        "##### application train test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRRcMM6dJlf9"
      },
      "outputs": [],
      "source": [
        "application = application[application['CODE_GENDER'] != 'XNA']\n",
        "\n",
        "nan_as_category = False\n",
        "for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
        "    application[bin_feature], uniques = pd.factorize(application[bin_feature])\n",
        "    # Categorical features with One-Hot encode\n",
        "application, cat_cols = one_hot_encoder(application, nan_as_category)\n",
        "\n",
        "# NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
        "application['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
        "# Some simple new features (percentages)\n",
        "application['DAYS_EMPLOYED_PERC'] = application['DAYS_EMPLOYED'] / application['DAYS_BIRTH']\n",
        "application['INCOME_CREDIT_PERC'] = application['AMT_INCOME_TOTAL'] / application['AMT_CREDIT']\n",
        "application['INCOME_PER_PERSON'] = application['AMT_INCOME_TOTAL'] / application['CNT_FAM_MEMBERS']\n",
        "application['ANNUITY_INCOME_PERC'] = application['AMT_ANNUITY'] / application['AMT_INCOME_TOTAL']\n",
        "application['PAYMENT_RATE'] = application['AMT_ANNUITY'] / application['AMT_CREDIT']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = application.copy()"
      ],
      "metadata": {
        "id": "p3EFjOLaV0Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del application"
      ],
      "metadata": {
        "id": "A0tCJTbnV10p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "XOTP6DSkJlf-"
      },
      "source": [
        "##### bureau and balance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "WXMX2lRMJlf-"
      },
      "outputs": [],
      "source": [
        "bureau_balance.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RK_7qmtNJlgA"
      },
      "outputs": [],
      "source": [
        "bureau_balance, bureau_balance_cat = one_hot_encoder(bureau_balance, nan_as_category=True)\n",
        "bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category=True) \n",
        "bureau_balance_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
        "for col in bureau_balance_cat:\n",
        "    bureau_balance_aggregations[col] = ['mean']\n",
        "bureau_balance_agg = bureau_balance.groupby('SK_ID_BUREAU').agg(bureau_balance_aggregations)\n",
        "bureau_balance_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bureau_balance_agg.columns.tolist()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "TmL5F3bIJlgF"
      },
      "outputs": [],
      "source": [
        "bureau = bureau.join(bureau_balance_agg, on=\"SK_ID_BUREAU\", how='left', lsuffix='', rsuffix='')#, on='SK_ID_BUREAU')\n",
        "bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "# Bureau and bureau_balance numeric features\n",
        "num_aggregations = {\n",
        "    'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
        "    'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
        "    'DAYS_CREDIT_UPDATE': ['mean'],\n",
        "    'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
        "    'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
        "    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
        "    'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
        "    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
        "    'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
        "    'AMT_ANNUITY': ['max', 'mean'],\n",
        "    'CNT_CREDIT_PROLONG': ['sum'],\n",
        "    'MONTHS_BALANCE_MIN': ['min'],\n",
        "    'MONTHS_BALANCE_MAX': ['max'],\n",
        "    'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
        "}\n",
        "# Bureau and bureau_balance categorical features\n",
        "cat_aggregations = {}\n",
        "for cat in bureau_cat: \n",
        "    cat_aggregations[cat] = ['mean']\n",
        "for cat in bureau_balance_cat: \n",
        "    cat_aggregations[cat + \"_MEAN\"] = ['mean']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "usSBjmdRJlgG"
      },
      "outputs": [],
      "source": [
        "bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
        "bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imor-4N3JlgH",
        "outputId": "124723f2-8795-4d15-e919-d02fd1f87754"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Bureau: Active credits - using only numerical aggregations\n",
        "active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
        "active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
        "active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
        "bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
        "del active, active_agg\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldQB8Cr0JlgH",
        "outputId": "0bd36fc4-9595-42b1-dca1-bab93411ace3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Bureau: Closed credits - using only numerical aggregations\n",
        "closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
        "closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
        "closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
        "bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.merge(bureau_agg, how='left', on=\"SK_ID_CURR\")\n",
        "del bureau_agg, closed_agg, closed, bureau, bureau_balance, bureau_balance_agg, bureau_balance_aggregations, bureau_cat, bureau_balance_cat"
      ],
      "metadata": {
        "id": "B3fAb0PMWYFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "XYUff-T5JlgI"
      },
      "source": [
        "##### Previous_applications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj8c6aQ2JlgI",
        "outputId": "88959bc4-f0cf-4429-d7db-07ec2cf414e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "previous, cat_cols = one_hot_encoder(previous, nan_as_category= True)\n",
        "# if Days == 365.243  -> nan : Pourquoi?\n",
        "previous['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
        "previous['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
        "previous['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
        "previous['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
        "previous['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
        "# Add feature: value ask / value received percentage\n",
        "previous['APP_CREDIT_PERC'] = previous['AMT_APPLICATION'] / previous['AMT_CREDIT']\n",
        "# Previous applications numeric features\n",
        "num_aggregations = {\n",
        "    'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
        "    'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
        "    'AMT_CREDIT': ['min', 'max', 'mean'],\n",
        "    'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
        "    'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
        "    'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
        "    'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
        "    'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
        "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
        "    'CNT_PAYMENT': ['mean', 'sum'],\n",
        "}\n",
        "# Previous applications categorical features\n",
        "cat_aggregations = {}\n",
        "for cat in cat_cols:\n",
        "    cat_aggregations[cat] = ['mean']\n",
        "\n",
        "prev_agg = previous.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
        "prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
        "# Previous Applications: Approved Applications - only numerical features\n",
        "approved = previous[previous['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
        "approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
        "approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
        "prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
        "# Previous Applications: Refused Applications - only numerical features\n",
        "refused = previous[previous['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
        "refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
        "refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
        "prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
        "del refused, refused_agg, approved, approved_agg\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.merge(prev_agg, how='left', on=\"SK_ID_CURR\")\n",
        "del previous, prev_agg"
      ],
      "metadata": {
        "id": "_eiu3l5vXiDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "bbvg92BgJlgJ"
      },
      "source": [
        "##### pos_cash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHK_D1TTJlgJ",
        "outputId": "9d0025fe-fc83-455d-871e-45bb35210e2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n",
        "# Features\n",
        "aggregations = {\n",
        "    'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
        "    'SK_DPD': ['max', 'mean'],\n",
        "    'SK_DPD_DEF': ['max', 'mean']\n",
        "}\n",
        "for cat in cat_cols:\n",
        "    aggregations[cat] = ['mean']\n",
        "\n",
        "pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
        "pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
        "# Count pos cash accounts\n",
        "pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.merge(pos_agg, how='left', on=\"SK_ID_CURR\")\n",
        "del pos, pos_agg"
      ],
      "metadata": {
        "id": "ZlOjuP-MX11Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Pad5hahpJlgJ"
      },
      "source": [
        "##### Installments_payments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KQIoEQrJlgJ",
        "outputId": "56fcaeed-d704-49b4-947c-900c27e251cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
        "# Percentage and difference paid in each installment (amount paid and installment value)\n",
        "ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
        "ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
        "# Days past due and days before due (no negative values)\n",
        "ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
        "ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
        "ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
        "ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
        "# Features: Perform aggregations\n",
        "aggregations = {\n",
        "    'NUM_INSTALMENT_VERSION': ['nunique'],\n",
        "    'DPD': ['max', 'mean', 'sum'],\n",
        "    'DBD': ['max', 'mean', 'sum'],\n",
        "    'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
        "    'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
        "    'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
        "    'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
        "    'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
        "}\n",
        "for cat in cat_cols:\n",
        "    aggregations[cat] = ['mean']\n",
        "ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
        "ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
        "# Count installments accounts\n",
        "ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.merge(ins_agg, how='left', on=\"SK_ID_CURR\")\n",
        "del ins, ins_agg"
      ],
      "metadata": {
        "id": "nrWY09DSX_83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH9_8ZttJlgJ"
      },
      "source": [
        "##### credit card balance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp01OmopJlgJ",
        "outputId": "a6c602d7-0196-4449-fe24-f8c97208ba7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
        "# General aggregations\n",
        "cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
        "cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
        "cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
        "# Count credit card lines\n",
        "cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.merge(cc_agg, how='left', on=\"SK_ID_CURR\")\n",
        "del cc, cc_agg"
      ],
      "metadata": {
        "id": "EIcMbOGrYQVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR1jKxrhJlgK"
      },
      "source": [
        "##### kfold lightgbm\n",
        "LightGBM GBDT with KFold or Stratified KFold  \n",
        "Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "QfRyHOD8JlgK"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import re\n",
        "\n",
        "def kfold_lightgbm(df, num_folds, stratified = False, debug= False):\n",
        "    # Divide in training/validation and test data\n",
        "    df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
        "    train_df = df[df['TARGET'].notnull()]\n",
        "    test_df = df[df['TARGET'].isnull()]\n",
        "    print(f\"Starting LightGBM. Train shape: {train_df.shape}, test shape: {test_df.shape}\")\n",
        "    del df\n",
        "    gc.collect()\n",
        "    # Cross validation model\n",
        "    if stratified:\n",
        "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
        "    else:\n",
        "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
        "    # Create arrays and dataframes to store results\n",
        "    oof_preds = np.zeros(train_df.shape[0])\n",
        "    sub_preds = np.zeros(test_df.shape[0])\n",
        "    feature_importance_df = pd.DataFrame()\n",
        "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
        "    \n",
        "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
        "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
        "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
        "\n",
        "        # LightGBM parameters found by Bayesian optimization\n",
        "        clf = LGBMClassifier(\n",
        "            nthread=4,\n",
        "            n_estimators=10000,\n",
        "            learning_rate=0.02,\n",
        "            num_leaves=34,\n",
        "            colsample_bytree=0.9497036,\n",
        "            subsample=0.8715623,\n",
        "            max_depth=8,\n",
        "            reg_alpha=0.041545473,\n",
        "            reg_lambda=0.0735294,\n",
        "            min_split_gain=0.0222415,\n",
        "            min_child_weight=39.3259775,\n",
        "            silent=-1,\n",
        "            verbose=-1, )\n",
        "        #print(f\"train_x: {train_x}, train_y: {train_y}, eval_set={[(train_x, train_y), (valid_x, valid_y)]}\")\n",
        "        #print(f\"train_x: {train_x.columns}, train_y : {train_y.tolist()}\")\n",
        "        #print(f\"valid_x : {valid_x.columns}, valid_y : {valid_y.tolist()}\")\n",
        "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
        "            eval_metric= 'auc', verbose=200, early_stopping_rounds = 200)\n",
        "\n",
        "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
        "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
        "\n",
        "        fold_importance_df = pd.DataFrame()\n",
        "        fold_importance_df[\"feature\"] = feats\n",
        "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
        "        print(f\"fold_importance_df: {clf.feature_importances_}\")\n",
        "        fold_importance_df[\"fold\"] = n_fold + 1\n",
        "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
        "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
        "        del clf, train_x, train_y, valid_x, valid_y\n",
        "        gc.collect()\n",
        "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
        "    # Write submission file and plot feature importance\n",
        "    if not debug:\n",
        "        test_df['TARGET'] = sub_preds\n",
        "        test_df[['SK_ID_CURR', 'TARGET']].to_csv(\"simulation_results.csv\", index= False)\n",
        "    display_importances(feature_importance_df)\n",
        "    return feature_importance_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPHcstnBJlgL"
      },
      "source": [
        "##### Affichage de l'importance des features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBdECuAiJlgL"
      },
      "outputs": [],
      "source": [
        "def display_importances(feature_importance_df_):\n",
        "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
        "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
        "    plt.figure(figsize=(8, 10))\n",
        "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
        "    plt.title('LightGBM Features (avg over folds)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('lgbm_importances01.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bATst-IOJlgL"
      },
      "outputs": [],
      "source": [
        "df = application.copy()\n",
        "df = df.merge(bureau_agg, how='left', on=\"SK_ID_CURR\")\n",
        "df = df.merge(previous, how='left', on=\"SK_ID_CURR\")\n",
        "df = df.merge(pos, how='left', on=\"SK_ID_CURR\")\n",
        "df = df.merge(ins, how='left', on=\"SK_ID_CURR\")\n",
        "df = df.merge(cc_agg, how='left', on=\"SK_ID_CURR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlI-RmqiJlgL"
      },
      "outputs": [],
      "source": [
        "del bureau_agg, previous, pos, ins, cc_agg\n",
        "df.to_csv(path + \"final_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(path + \"final_data.csv\")"
      ],
      "metadata": {
        "id": "UdfZwgGaalKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoJPl0nsJlgM"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYBKlsovJlgM"
      },
      "outputs": [],
      "source": [
        "df[\"TARGET\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HNSrHcAJlgM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "tags": [],
        "id": "YRaIw_vPJlgN"
      },
      "source": [
        "feat_importance = kfold_lightgbm(df, num_folds= 10, stratified= False)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "80079d8dd9f7c252f0ff3be33272006cb63eba2cb77317ddc2afd11fdc1d0064"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}