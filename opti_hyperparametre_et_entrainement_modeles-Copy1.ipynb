{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7840510d-a150-4926-9e9c-4a681ec765aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import mlflow\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dd0c91-2ebd-4698-8fcf-89f67f2e292b",
   "metadata": {},
   "source": [
    "## Séparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63055f91-6b57-480e-804c-f0c5ca9b452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(\"utils_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c216b2c-811e-4e6f-aa29-b05f2f95c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "new_df = new_df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f863cc5f-357e-40fe-9c7d-f9cc45ecd7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.set_index('SK_ID_CURR', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0eb1973-b93b-433f-9e3e-cd6d20a117a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop(columns='TARGET')\n",
    "y = new_df['TARGET']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = pd.DataFrame(scaler.transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48ca7df9-c2b1-420d-a398-f33aecb39a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d46527-da6c-4c8c-ae7b-1c2b7282fc48",
   "metadata": {},
   "source": [
    "## Équilibrage des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "866412a1-75d3-4bee-b05b-ddebe3c4fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "922a9d05-fa50-4fe2-b276-6c7f34b6b5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 197863, 1: 17391}) Counter({0: 197863, 1: 197863})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "counter_before = Counter(y_train)\n",
    "counter_after = Counter(y_train_over)\n",
    "print(counter_before, counter_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065a4a9a-6d00-4bc2-a07c-e623cdb4df6f",
   "metadata": {},
   "source": [
    "## Entrainement des modèles\n",
    "### Réduction des données\n",
    "En l'état les données sont trop volumineuses pour pouvoir entrainer les modèles. Nous pouvons les réduire en utilisant la méthode sample() d'un dataframe pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9211fcb2-7dbe-4fa8-a160-8dc23e3ec532",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_sample = X_train_over.merge(y_train_over, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bdc77b2-41ae-42a6-ab40-e7546d06f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_sample = to_sample.sample(frac=0.2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afda98fc-8194-4e81-92c6-c35e943512da",
   "metadata": {},
   "source": [
    "X_train_sample = to_sample.drop(columns='TARGET')\n",
    "y_train_sample = to_sample['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "051e68ea-597f-45ec-8df1-d6bce2f373a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = to_sample.drop(columns='TARGET')\n",
    "y_train = to_sample['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce54a9c-0693-4f7e-900a-fb7aa6b3b05a",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40d692a5-e222-4dc1-8360-597d0246e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a602f124-11f0-4379-94cc-29384410789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "kfolds = KFold(n_splits=5, shuffle=True, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "184f6583-a5c7-4dee-a204-ffa5b08dcad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tune(objective, study_name):\n",
    "    study = optuna.create_study(study_name=study_name, direction='maximize')\n",
    "    \n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    params = study.best_params\n",
    "    best_score = study.best_value\n",
    "    return params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "277882ff-a2e3-40df-93bc-23c3b23192da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_objective(trial):\n",
    "    _C = trial.suggest_float('C', 0.01, 100)\n",
    "    \n",
    "    clf_log = LogisticRegression(C=_C, random_state=random_seed)\n",
    "    \n",
    "    score = cross_val_score(clf_log, X_train, y_train, cv=kfolds, scoring='roc_auc').mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e8cb5d1-8f44-4389-84a3-eddf49f1bcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/matth/Documents/openclassroom/data_scientist/P7/mlruns/747928904526590890', creation_time=1672240642707, experiment_id='747928904526590890', last_update_time=1672240642707, lifecycle_stage='active', name='optimisation hyperparamètre et entrainement des modèles', tags={}>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment('optimisation hyperparamètre et entrainement des modèles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad186719-e3d2-4fdf-81af-4314e1a900e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-11 12:52:31,502]\u001b[0m A new study created in memory with name: log_reg\u001b[0m\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-01-11 12:52:38,559]\u001b[0m Trial 0 finished with value: 0.7915608736539694 and parameters: {'C': 88.24273150918484}. Best is trial 0 with value: 0.7915608736539694.\u001b[0m\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-01-11 12:52:44,658]\u001b[0m Trial 1 finished with value: 0.7915612883452067 and parameters: {'C': 55.210259661759224}. Best is trial 1 with value: 0.7915612883452067.\u001b[0m\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-01-11 12:52:50,214]\u001b[0m Trial 2 finished with value: 0.7915618536394876 and parameters: {'C': 14.626170229992706}. Best is trial 2 with value: 0.7915618536394876.\u001b[0m\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-01-11 12:52:54,558]\u001b[0m Trial 3 finished with value: 0.7915603817073704 and parameters: {'C': 49.42452678688535}. Best is trial 2 with value: 0.7915618536394876.\u001b[0m\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-01-11 12:52:58,755]\u001b[0m Trial 4 finished with value: 0.7915624220911928 and parameters: {'C': 47.05618128427412}. Best is trial 4 with value: 0.7915624220911928.\u001b[0m\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-01-11 12:53:02,754]\u001b[0m Trial 5 finished with value: 0.7915607902875611 and parameters: {'C': 68.82883018199054}. Best is trial 4 with value: 0.7915624220911928.\u001b[0m\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-01-11 12:53:06,844]\u001b[0m Trial 6 finished with value: 0.7915628912954821 and parameters: {'C': 41.945764652293775}. Best is trial 6 with value: 0.7915628912954821.\u001b[0m\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-01-11 12:53:11,462]\u001b[0m Trial 7 finished with value: 0.7915576165688283 and parameters: {'C': 77.5618566610786}. Best is trial 6 with value: 0.7915628912954821.\u001b[0m\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-01-11 12:53:15,835]\u001b[0m Trial 8 finished with value: 0.7915630223870929 and parameters: {'C': 55.595799074476204}. Best is trial 8 with value: 0.7915630223870929.\u001b[0m\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-01-11 12:53:20,012]\u001b[0m Trial 9 finished with value: 0.7915617578797491 and parameters: {'C': 97.40644214930536}. Best is trial 8 with value: 0.7915630223870929.\u001b[0m\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"Logistic regression\"):\n",
    "    params = {}\n",
    "    params['MODEL_NAME'] = 'logistic_regression'\n",
    "    params['TRAIN_SIZE'] = len(X_train)\n",
    "    \n",
    "    start = time.time()\n",
    "    log_params, log_score = tune(log_reg_objective, 'log_reg')\n",
    "    params['time'] = time.time() - start\n",
    "    \n",
    "    params['C'] = log_params['C']\n",
    "    params['train_roc_auc'] = log_score\n",
    "    train_roc_auc = log_score\n",
    "    mlflow.log_metric('train_roc_auc', train_roc_auc) \n",
    "    train_roc_auc = log_score\n",
    "    \n",
    "    # On entraine le modèle avec les paramètres retournés\n",
    "    clf_log = LogisticRegression(C=params['C'])\n",
    "    clf_log.fit(X_train, y_train)\n",
    "    \n",
    "    # On calcul le score final du modele avec les données de test\n",
    "    y_pred = clf_log.predict(X_test)\n",
    "    params['test_roc_auc'] = roc_auc_score(y_test, y_pred)\n",
    "    mlflow.log_metric('test_roc_auc',roc_auc_score(y_test, y_pred))\n",
    "    \n",
    "    # calcul de la matrice de confusion\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    cm = sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='d')\n",
    "    plt.title(\"Matrice de confusion avec le cout statistique\")\n",
    "    plt.savefig(\"confusion_matrix_hors_metier.png\")\n",
    "\n",
    "    mlflow.log_artifact(local_path=\"confusion_matrix_hors_metier.png\")\n",
    "    mlflow.log_params(params)\n",
    "    # On sauvegarde le model pour l'utiliser dans le futur sans avoir à l'entrainer de nouveau\n",
    "    mlflow.sklearn.log_model(clf_log, 'log_reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aae0d0-25f3-43a4-bfa9-24b1b18cba5d",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63e6361a-3491-436a-8ad8-4ea3a9b7dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def randomforest_objective(trial):\n",
    "    _n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
    "    _max_depth = trial.suggest_int(\"max_depth\", 5, 10)\n",
    "    \n",
    "    \n",
    "    clf_forest = RandomForestClassifier(max_depth=_max_depth,\n",
    "                                        n_estimators=_n_estimators,\n",
    "                                        random_state=random_seed)\n",
    "    \n",
    "    score = cross_val_score(clf_forest,\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            cv=kfolds,\n",
    "                            scoring='roc_auc').mean()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edc08106-0a55-45e1-b4fa-9209727fc8a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 16:18:24,948]\u001b[0m A new study created in memory with name: log_reg\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 16:19:29,564]\u001b[0m Trial 0 finished with value: 0.9119124131897799 and parameters: {'n_estimators': 61, 'max_depth': 6}. Best is trial 0 with value: 0.9119124131897799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 16:21:18,416]\u001b[0m Trial 1 finished with value: 0.9464632727402644 and parameters: {'n_estimators': 65, 'max_depth': 10}. Best is trial 1 with value: 0.9464632727402644.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 16:23:04,974]\u001b[0m Trial 2 finished with value: 0.9387903948551776 and parameters: {'n_estimators': 70, 'max_depth': 9}. Best is trial 1 with value: 0.9464632727402644.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 16:25:14,302]\u001b[0m Trial 3 finished with value: 0.9316418840029149 and parameters: {'n_estimators': 94, 'max_depth': 8}. Best is trial 1 with value: 0.9464632727402644.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 16:30:01,457]\u001b[0m Trial 4 finished with value: 0.9471277083622139 and parameters: {'n_estimators': 185, 'max_depth': 10}. Best is trial 4 with value: 0.9471277083622139.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 16:31:46,167]\u001b[0m Trial 5 finished with value: 0.9464580456152575 and parameters: {'n_estimators': 68, 'max_depth': 10}. Best is trial 4 with value: 0.9471277083622139.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 16:33:04,228]\u001b[0m Trial 6 finished with value: 0.9371309746671453 and parameters: {'n_estimators': 52, 'max_depth': 9}. Best is trial 4 with value: 0.9471277083622139.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 16:36:54,545]\u001b[0m Trial 7 finished with value: 0.932177275785137 and parameters: {'n_estimators': 179, 'max_depth': 8}. Best is trial 4 with value: 0.9471277083622139.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 16:38:55,162]\u001b[0m Trial 8 finished with value: 0.9216641111794267 and parameters: {'n_estimators': 108, 'max_depth': 7}. Best is trial 4 with value: 0.9471277083622139.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 16:40:56,230]\u001b[0m Trial 9 finished with value: 0.9216641111794267 and parameters: {'n_estimators': 108, 'max_depth': 7}. Best is trial 4 with value: 0.9471277083622139.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"Random Forest\"):\n",
    "    params = {}\n",
    "    params['MODEL_NAME'] = 'Random Forest'\n",
    "    params['TRAIN_SIZE'] = len(X_train)\n",
    "    \n",
    "    # Optimisation des hyperparamètres\n",
    "    start = time.time()\n",
    "    forest_params, forest_score = tune(randomforest_objective)\n",
    "    params['time'] = time.time() - start\n",
    "    \n",
    "    params['n_estimators'] = forest_params['n_estimators']\n",
    "    params['max_depth'] = forest_params['max_depth']\n",
    "    train_roc_auc = forest_score\n",
    "    mlflow.log_metric('train_roc_auc', train_roc_auc)\n",
    "    \n",
    "    # On entraine le modèle avec les paramètres retournés\n",
    "    clf_forest = RandomForestClassifier(n_estimators=params['n_estimators'],\n",
    "                                        max_depth=params['max_depth'],\n",
    "                                        random_state=random_seed)\n",
    "    clf_forest.fit(X_train, y_train)\n",
    "    \n",
    "    # On calcule le score final du modele avec les données test\n",
    "    y_pred = clf_forest.predict(X_test)\n",
    "    mlflow.log_metric('test_roc_auc',roc_auc_score(y_test, y_pred))\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # On sauvegarde le modele\n",
    "    mlflow.sklearn.log_model(clf_forest, 'Random forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cfa5bc-634c-4f02-b754-3bf1e67b255b",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97e353b1-89ff-4409-8c03-17cefd7d4b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def xgboost_objective(trial):\n",
    "    _n_estimators = trial.suggest_int(\"n_estimator\", 10, 100, 10)\n",
    "    _max_depth = trial.suggest_int('max_depth', 5, 25, 2)\n",
    "    #_learning_rate = trial.suggest_float('learning_rate', 0.01, 0.1, step=0.01)\n",
    "    \n",
    "    \n",
    "    clf_boost = GradientBoostingClassifier(max_depth=_max_depth,\n",
    "                                           n_estimators=_n_estimators,\n",
    "                                           #learning_rate=_learning_rate,\n",
    "                                           random_state=random_seed)\n",
    "    \n",
    "    score = cross_val_score(clf_boost, X_train, y_train, cv=kfolds, scoring='roc_auc').mean()\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13a2216-dd33-4d12-98ec-565ae8479f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('optimisation cout metier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7ff1c-f30a-4f77-a049-5d8e4394e53f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-04 12:03:18,623]\u001b[0m A new study created in memory with name: xgboost\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 12:58:48,522]\u001b[0m Trial 0 finished with value: 0.9780936735321244 and parameters: {'n_estimator': 100, 'max_depth': 11}. Best is trial 0 with value: 0.9780936735321244.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 13:43:31,515]\u001b[0m Trial 1 finished with value: 0.9783889462472363 and parameters: {'n_estimator': 70, 'max_depth': 13}. Best is trial 1 with value: 0.9783889462472363.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 13:45:59,678]\u001b[0m Trial 2 finished with value: 0.9342093088373022 and parameters: {'n_estimator': 10, 'max_depth': 5}. Best is trial 1 with value: 0.9783889462472363.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 13:53:09,011]\u001b[0m Trial 3 finished with value: 0.9631364863661851 and parameters: {'n_estimator': 30, 'max_depth': 5}. Best is trial 1 with value: 0.9783889462472363.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 14:32:50,833]\u001b[0m Trial 4 finished with value: 0.9774930891104046 and parameters: {'n_estimator': 70, 'max_depth': 11}. Best is trial 1 with value: 0.9783889462472363.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 14:49:10,003]\u001b[0m Trial 5 finished with value: 0.9628847511096567 and parameters: {'n_estimator': 20, 'max_depth': 17}. Best is trial 1 with value: 0.9783889462472363.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 14:55:53,180]\u001b[0m Trial 6 finished with value: 0.9624095835207275 and parameters: {'n_estimator': 20, 'max_depth': 7}. Best is trial 1 with value: 0.9783889462472363.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 16:08:13,154]\u001b[0m Trial 7 finished with value: 0.9800381776037966 and parameters: {'n_estimator': 100, 'max_depth': 15}. Best is trial 7 with value: 0.9800381776037966.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"xgboost\"):\n",
    "    params = {}\n",
    "    params['MODEL_NAME'] = 'xgboost'\n",
    "    params['TRAIN_SIZE'] = len(X_train)\n",
    "    \n",
    "    start = time.time()\n",
    "    xgboost_params, xgboost_score = tune(xgboost_objective, study_name='xgboost')\n",
    "    params['time'] = time.time() - start\n",
    "    \n",
    "    params['n_estimators'] = xgboost_params['n_estimators']\n",
    "    params['max_depth'] = xgboost_params['max_depth']\n",
    "    #params['learning_rate'] = xgboost_params['learning_rate']\n",
    "    train_roc_auc = xgboost_score\n",
    "    mlflow.log_metric('train_roc_auc', train_roc_auc)\n",
    "    \n",
    "    # On entraine le modèle avec les paramètres retournés\n",
    "    clf_boost = GradientBoostingClassifier(n_estimators=params['n_estimators'],\n",
    "                                           max_depth=params['max_depth'],\n",
    "                                           #learning_rate=params['learning_rate'],\n",
    "                                           random_state=random_seed)\n",
    "    clf_boost.fit(X_train, y_train)\n",
    "    \n",
    "    # on calcule le score final\n",
    "    y_pred = clf_boost.predict(X_test)\n",
    "    mlflow.log_metric('test_roc_auc', roc_auc_score(y_test, y_pred))\n",
    "     \n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # On sauvegarde le modèle\n",
    "    mlflow.sklearn.log_model(clf_boost, 'XGBOOST')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9c1c35-c3b5-4163-9d54-4f512623c5f1",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcfe4b4d-a7b9-437f-805e-89e1df02fed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "def lightgbm_objective(trial):\n",
    "    _num_leaves = trial.suggest_int(\"num_leaves\", 50, 100)\n",
    "    _max_depth = trial.suggest_int(\"max_depth\", 1, 20)\n",
    "    _learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 1)\n",
    "    _n_estimators = trial.suggest_int(\"n_estimators\", 50, 2000)\n",
    "    _min_child_weight = trial.suggest_float(\"min_child_weight\", 0.1, 10)\n",
    "    _reg_alpha = trial.suggest_float('reg_alpha', 0.01, 10)\n",
    "    _reg_lambda = trial.suggest_float('reg_lambda', 0.01, 10)\n",
    "    _subsample = trial.suggest_float('subsample', 0.01, 1)\n",
    "    \n",
    "    \n",
    "    clf_lightgbm = LGBMClassifier(\n",
    "                                  num_leaves=_num_leaves,\n",
    "                                  max_depth=_max_depth,\n",
    "                                  learning_rate=_learning_rate,\n",
    "                                  n_estimators=_n_estimators,\n",
    "                                  min_child_weight=_min_child_weight,\n",
    "                                  subsample=_subsample,\n",
    "                                  reg_alpha=_reg_alpha,\n",
    "                                  reg_lambda=_reg_lambda,\n",
    "                                  random_state=random_seed,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    score = cross_val_score(clf_lightgbm, X_train, y_train, cv=kfolds, scoring='roc_auc').mean()\n",
    "    \n",
    "    return score\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11910ee3-76db-4997-8bd4-8638e8a9c31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-04 16:56:17,151]\u001b[0m A new study created in memory with name: lightgbm\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 16:58:20,929]\u001b[0m Trial 0 finished with value: 0.9772113205102875 and parameters: {'num_leaves': 65, 'max_depth': 5, 'learning_rate': 0.070429067290123, 'n_estimators': 1948, 'min_child_weight': 5.109067046621498, 'reg_alpha': 6.372934911029781, 'reg_lambda': 7.917585220303045, 'subsample': 0.2719627749838453}. Best is trial 0 with value: 0.9772113205102875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 16:58:33,702]\u001b[0m Trial 1 finished with value: 0.9770049119107733 and parameters: {'num_leaves': 86, 'max_depth': 3, 'learning_rate': 0.2840977927132267, 'n_estimators': 262, 'min_child_weight': 1.1063609272991082, 'reg_alpha': 2.2975188923242045, 'reg_lambda': 5.556815899726475, 'subsample': 0.031126658685631817}. Best is trial 0 with value: 0.9772113205102875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 16:59:01,477]\u001b[0m Trial 2 finished with value: 0.975200691063123 and parameters: {'num_leaves': 66, 'max_depth': 14, 'learning_rate': 0.5419495407710921, 'n_estimators': 570, 'min_child_weight': 7.848563693869069, 'reg_alpha': 5.925841356025272, 'reg_lambda': 7.9928609802624075, 'subsample': 0.17801627044577986}. Best is trial 0 with value: 0.9772113205102875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 16:59:48,920]\u001b[0m Trial 3 finished with value: 0.9776374484639465 and parameters: {'num_leaves': 83, 'max_depth': 16, 'learning_rate': 0.1676109150247204, 'n_estimators': 776, 'min_child_weight': 6.11279706949136, 'reg_alpha': 8.045933627364741, 'reg_lambda': 8.010585967743712, 'subsample': 0.17971387709779318}. Best is trial 3 with value: 0.9776374484639465.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 17:00:24,390]\u001b[0m Trial 4 finished with value: 0.9762782366326143 and parameters: {'num_leaves': 84, 'max_depth': 9, 'learning_rate': 0.353065056946718, 'n_estimators': 351, 'min_child_weight': 6.119212563622858, 'reg_alpha': 2.960207628901846, 'reg_lambda': 6.716269658456772, 'subsample': 0.1298672753032875}. Best is trial 3 with value: 0.9776374484639465.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 17:01:18,281]\u001b[0m Trial 5 finished with value: 0.9764333897197283 and parameters: {'num_leaves': 94, 'max_depth': 14, 'learning_rate': 0.3724912067957032, 'n_estimators': 1592, 'min_child_weight': 8.149368822368757, 'reg_alpha': 5.325529522720447, 'reg_lambda': 7.450705370960876, 'subsample': 0.43394515989263516}. Best is trial 3 with value: 0.9776374484639465.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 17:02:22,673]\u001b[0m Trial 6 finished with value: 0.9773432271853875 and parameters: {'num_leaves': 60, 'max_depth': 9, 'learning_rate': 0.14843086071851802, 'n_estimators': 586, 'min_child_weight': 1.0416377333537534, 'reg_alpha': 4.847629322132786, 'reg_lambda': 8.359291269188159, 'subsample': 0.352571476526596}. Best is trial 3 with value: 0.9776374484639465.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 17:03:14,701]\u001b[0m Trial 7 finished with value: 0.9737926515952463 and parameters: {'num_leaves': 59, 'max_depth': 14, 'learning_rate': 0.7418038837979201, 'n_estimators': 1635, 'min_child_weight': 7.085163569702138, 'reg_alpha': 2.5587333513512416, 'reg_lambda': 2.0199713588160506, 'subsample': 0.5996353423874823}. Best is trial 3 with value: 0.9776374484639465.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 17:03:20,854]\u001b[0m Trial 8 finished with value: 0.9744581964214956 and parameters: {'num_leaves': 68, 'max_depth': 4, 'learning_rate': 0.786202462660456, 'n_estimators': 63, 'min_child_weight': 6.814776131252214, 'reg_alpha': 7.234959841299178, 'reg_lambda': 3.901151680977903, 'subsample': 0.7942392501674669}. Best is trial 3 with value: 0.9776374484639465.\u001b[0m\n",
      "\u001b[32m[I 2023-01-04 17:03:37,428]\u001b[0m Trial 9 finished with value: 0.9768786565147802 and parameters: {'num_leaves': 56, 'max_depth': 17, 'learning_rate': 0.06052134308847612, 'n_estimators': 100, 'min_child_weight': 4.621562715437391, 'reg_alpha': 7.027725195588294, 'reg_lambda': 7.803923405901197, 'subsample': 0.1599770101987713}. Best is trial 3 with value: 0.9776374484639465.\u001b[0m\n",
      "C:\\Users\\matth\\miniconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='light gbm'):\n",
    "    params = {}\n",
    "    params['MODEL_NAME'] = 'light gbm'\n",
    "    params['TRAIN_SIZE'] = len(X_train)\n",
    "    \n",
    "    start = time.time()\n",
    "    lgbmt_params, lgbm_score = tune(lightgbm_objective, study_name='lightgbm')\n",
    "    params['time'] = time.time() - start\n",
    "    \n",
    "    params['n_estimators'] = lgbmt_params['n_estimators']\n",
    "    params['max_depth'] = lgbmt_params['max_depth']\n",
    "    params['learning_rate'] = lgbmt_params['learning_rate']\n",
    "    params['num leaves'] = lgbmt_params['num_leaves']\n",
    "    params['min child weight'] = lgbmt_params['min_child_weight']\n",
    "    params['reg alpha'] = lgbmt_params['reg_alpha']\n",
    "    params['reg lambda'] = lgbmt_params['reg_lambda']\n",
    "    params['subsample'] = lgbmt_params['subsample']\n",
    "    mlflow.log_metric('train_roc_auc', lgbm_score)\n",
    "    \n",
    "    # On entraine le modèle avec les paramètres retournés\n",
    "    clf_lgbm = LGBMClassifier(n_estimators=params['n_estimators'],\n",
    "                              max_depth=params['max_depth'],\n",
    "                              learning_rate=params['learning_rate'],\n",
    "                              num_leaves=params['num leaves'],\n",
    "                              min_child_weight=params['min child weight'],\n",
    "                              reg_alpha=params['reg alpha'],\n",
    "                              reg_lambda=params['reg lambda'],\n",
    "                              subsample=params['subsample'],\n",
    "                              random_state=random_seed)\n",
    "    clf_lgbm.fit(X_train, y_train)\n",
    "    \n",
    "    # On calcule le score final\n",
    "    y_pred = clf_lgbm.predict(X_test)\n",
    "    mlflow.log_metric('test_roc_auc', roc_auc_score(y_test, y_pred))\n",
    "    \n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # On sauvegarde le modèle\n",
    "    mlflow.sklearn.log_model(clf_lgbm, 'LGBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f6c37-6b53-4fb0-b790-3264df55e2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
